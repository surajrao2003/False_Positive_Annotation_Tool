# False Positive Annotation Review Tool

## Overview
The **False Positive Annotation Review Tool** helps you quickly review and manage false positive predictions generated by machine learning models (e.g., Grounding DINO) in the **COCO dataset format**. You can accept, reject, or edit bounding box annotations using simple keyboard shortcuts, speeding up the process of improving model predictions without manual annotation.

## Workflow
1. **Generate False Positives**: Use model predictions to identify false positives.
2. **Review False Positives**: Review and filter false positives using this tool.
3. **Merge Accepted Annotations**: Merge the accepted false positives with your original ground truth dataset.

## Keyboard Shortcuts
- `a`: Accept the current bounding box annotation
- `r`: Reject the current bounding box annotation
- `n`: Skip the current annotation without decision
- `p`: Go to the previous annotation
- `e`: Edit the annotation category
- `q`: Quit and save reviewed annotations

## Visual Indicators
- **Blue Box**: Unreviewed annotation
- **Green Box**: Accepted annotation
- **Red Box**: Rejected annotation

## Prerequisites
- Python 3.x
- OpenCV
- tkinter

## Usage

### Step 1: Prepare Your Dataset and Annotations
- Ensure your dataset is in **COCO format**.
- Run **`false_positives_extractor.py`** to generate false positives from model predictions and ground truth annotations.

### Step 2: Configure Paths
Update the paths in the script to point to your dataset and annotation files:

```python
DATASET_PATH = "path/to/images"
INPUT_JSON = "path/to/false_positives.json"  # Generated by false_positives_extractor.py
OUTPUT_JSON = "reviewed_annotations.json"
```
### Step 3: Run the Script
Execute the **False Positive Annotation Review Tool** script:

```bash
python annotation-review-tool.py
```

### Step 4: Review Annotations
Review the generated false positives interactively:
- Use keyboard shortcuts to accept, reject, or edit annotations.
- The tool displays images with bounding boxes, and you can track your review decisions.

### Step 5: Save and Merge
Once finished, the accepted false positives will be saved in the output JSON file. Merge this file with your original ground truth annotations to update the dataset.

## Conclusion
Designed to save time by allowing quick review of model-generated false positives, minimizing manual annotation effort.
